"""
åŒ»ç–—å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ - FastAPI åç«¯æœåŠ¡
æä¾›æ‚£è€…ç®¡ç†å’ŒAIå¯¹è¯æ¥å£
"""

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import uuid
import sys
import os
from pathlib import Path
import json
import asyncio
import shutil

# æ·»åŠ Agentç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'Agent'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Construct'))

# å¯¼å…¥å…¨å±€é…ç½®
from config import get_path, PATHS

from Agent.patient_model import patient_manager, PatientData
from Agent.flow import graph
from langchain_core.messages import HumanMessage

# å¯¼å…¥çŸ¥è¯†å›¾è°±å·¥ä½œæµ
try:
    from Construct.knowledge_workflow import KnowledgeWorkflow
except ImportError:
    KnowledgeWorkflow = None
    print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ KnowledgeWorkflowï¼ŒçŸ¥è¯†å›¾è°±åŠŸèƒ½å°†ä¸å¯ç”¨")

# å¯¼å…¥ç—‡çŠ¶å‘é‡åŒ–å·¥å…·
try:
    from Construct.symptom_vectorizer import SymptomVectorizer
except ImportError:
    SymptomVectorizer = None
    print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ SymptomVectorizerï¼Œç—‡çŠ¶å‘é‡åŒ–åŠŸèƒ½å°†ä¸å¯ç”¨")

# å¯¼å…¥çŸ¥è¯†å›¾è°±RAGå‘é‡åŒ–å·¥å…·
try:
    from Construct.knowledge_rag_vectorizer import KnowledgeRAGVectorizer
except ImportError:
    KnowledgeRAGVectorizer = None
    print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ KnowledgeRAGVectorizerï¼ŒRAGå‘é‡åŒ–åŠŸèƒ½å°†ä¸å¯ç”¨")

# å¯¼å…¥æ•°æ®ä¸€è‡´æ€§ç®¡ç†å™¨
try:
    from Construct.knowledge_data_manager import get_data_manager
    from config import NEO4J_CONFIG, REDIS_CONFIG
    
    # ä½¿ç”¨å…¨å±€é…ç½®è€Œéç¡¬ç¼–ç 
    data_manager = get_data_manager(
        redis_host=REDIS_CONFIG['host'],
        redis_port=REDIS_CONFIG['port'],
        redis_password=REDIS_CONFIG['password'],
        neo4j_uri=NEO4J_CONFIG['uri'],
        neo4j_user=NEO4J_CONFIG['user'],
        neo4j_password=NEO4J_CONFIG['password']
    )
except ImportError as e:
    data_manager = None
    print(f"è­¦å‘Šï¼šæ— æ³•å¯¼å…¥æ•°æ®ç®¡ç†å™¨ï¼Œæ•°æ®ä¸€è‡´æ€§åŠŸèƒ½å°†ä¸å¯ç”¨: {e}")
except Exception as e:
    data_manager = None
    print(f"è­¦å‘Šï¼šæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(title="åŒ»ç–—å¤šæ™ºèƒ½ä½“ç³»ç»ŸAPI", version="1.0.0")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# è¯·æ±‚/å“åº”æ¨¡å‹
# ============================================================================

class CreatePatientRequest(BaseModel):
    """åˆ›å»ºæ‚£è€…è¯·æ±‚"""
    patient_name: str
    patient_age: int
    patient_gender: Optional[str] = "ç”·"
    initial_symptoms: Optional[str] = None


class UpdatePatientRequest(BaseModel):
    """æ›´æ–°æ‚£è€…è¯·æ±‚"""
    patient_name: Optional[str] = None
    patient_age: Optional[int] = None
    patient_gender: Optional[str] = None
    initial_symptoms: Optional[str] = None
    patient_history: Optional[str] = None
    test_results: Optional[str] = None


class ChatRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚"""
    patient_id: str
    message: str


class ChatResponse(BaseModel):
    """å¯¹è¯å“åº”"""
    response: str
    patient_data: Dict[str, Any]


class SubmitTestResultsRequest(BaseModel):
    """æäº¤æ£€æŸ¥ç»“æœè¯·æ±‚"""
    submitted_tests: List[Dict[str, Any]]  # æ¯ä¸ªæ£€æŸ¥åŒ…å«test_nameã€test_descriptionã€result


class ExtractEntitiesRequest(BaseModel):
    """å®ä½“æŠ½å–è¯·æ±‚"""
    document_name: str


class BuildGraphRequest(BaseModel):
    """æ„å»ºçŸ¥è¯†å›¾è°±è¯·æ±‚"""
    document_name: str
    entities: List[Dict[str, Any]]
    relationships: List[Dict[str, Any]]


# ============================================================================
# æ‚£è€…ç®¡ç†æ¥å£
# ============================================================================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "åŒ»ç–—å¤šæ™ºèƒ½ä½“ç³»ç»ŸAPI", "version": "1.0.0"}


@app.get("/api/patients", response_model=List[Dict[str, Any]])
async def get_all_patients():
    """è·å–æ‰€æœ‰æ‚£è€…åˆ—è¡¨"""
    try:
        patient_dir = Path("patient_data")
        if not patient_dir.exists():
            return []
        
        patients = []
        for file_path in patient_dir.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    patient_data = json.load(f)
                    # åªè¿”å›åŸºæœ¬ä¿¡æ¯ç”¨äºåˆ—è¡¨æ˜¾ç¤º
                    patients.append({
                        "patient_id": patient_data.get("patient_id"),
                        "patient_name": patient_data.get("patient_name", "æœªå‘½åæ‚£è€…"),
                        "patient_age": patient_data.get("patient_age"),
                        "patient_gender": patient_data.get("patient_gender", "ç”·"),
                        "created_at": patient_data.get("created_at"),
                        "updated_at": patient_data.get("updated_at"),
                        "initial_symptoms": patient_data.get("initial_symptoms", "")[:50] + "..." if patient_data.get("initial_symptoms") else ""
                    })
            except Exception as e:
                print(f"è¯»å–æ‚£è€…æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                continue
        
        # æŒ‰æ›´æ–°æ—¶é—´é™åºæ’åˆ—
        patients.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
        return patients
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ‚£è€…åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/patients/{patient_id}", response_model=Dict[str, Any])
async def get_patient(patient_id: str):
    """è·å–å•ä¸ªæ‚£è€…çš„å®Œæ•´ä¿¡æ¯"""
    try:
        patient_data = patient_manager.load_patient_data(patient_id)
        if patient_data is None:
            raise HTTPException(status_code=404, detail="æ‚£è€…ä¸å­˜åœ¨")
        
        return patient_data.model_dump(exclude_none=False)
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ‚£è€…ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.post("/api/patients", response_model=Dict[str, Any])
async def create_patient(request: CreatePatientRequest):
    """åˆ›å»ºæ–°æ‚£è€…"""
    try:
        # ç”Ÿæˆæ–°çš„æ‚£è€…IDï¼ˆåŒæ—¶ä½œä¸ºthread_idä½¿ç”¨ï¼‰
        patient_id = str(uuid.uuid4())
        
        # åˆ›å»ºæ‚£è€…æ•°æ®
        patient_data = PatientData(
            patient_id=patient_id,
            patient_name=request.patient_name,
            patient_age=request.patient_age,
            patient_gender=request.patient_gender,
            initial_symptoms=request.initial_symptoms
        )
        
        # ä¿å­˜æ‚£è€…æ•°æ®
        patient_manager.save_patient_data(patient_data)
        
        result_dict = patient_data.model_dump(exclude_none=False)
        print(f">>> æ–°å»ºæ‚£è€…: {request.patient_name}, ID: {patient_id}, æ€§åˆ«: {request.patient_gender}")
        
        return result_dict
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæ‚£è€…å¤±è´¥: {str(e)}")


@app.put("/api/patients/{patient_id}", response_model=Dict[str, Any])
async def update_patient(patient_id: str, request: UpdatePatientRequest):
    """æ›´æ–°æ‚£è€…ä¿¡æ¯"""
    try:
        patient_data = patient_manager.load_patient_data(patient_id)
        if patient_data is None:
            raise HTTPException(status_code=404, detail="æ‚£è€…ä¸å­˜åœ¨")
        
        # æ›´æ–°å­—æ®µ
        update_fields = request.model_dump(exclude_none=True)
        for key, value in update_fields.items():
            setattr(patient_data, key, value)
        
        # ä¿å­˜æ›´æ–°
        patient_manager.save_patient_data(patient_data)
        
        return patient_data.model_dump(exclude_none=False)
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°æ‚£è€…å¤±è´¥: {str(e)}")


@app.delete("/api/patients/{patient_id}")
async def delete_patient(patient_id: str):
    """åˆ é™¤æ‚£è€…"""
    try:
        file_path = patient_manager.get_patient_file_path(patient_id)
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="æ‚£è€…ä¸å­˜åœ¨")
        
        file_path.unlink()
        return {"message": "æ‚£è€…å·²åˆ é™¤", "patient_id": patient_id}
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ‚£è€…å¤±è´¥: {str(e)}")


@app.post("/api/patients/{patient_id}/submit-tests", response_model=Dict[str, Any])
async def submit_test_results(patient_id: str, request: SubmitTestResultsRequest):
    """æäº¤æ£€æŸ¥ç»“æœ"""
    try:
        # éªŒè¯æ‚£è€…æ˜¯å¦å­˜åœ¨
        patient_data = patient_manager.load_patient_data(patient_id)
        if patient_data is None:
            raise HTTPException(status_code=404, detail="æ‚£è€…ä¸å­˜åœ¨")
        
        # éªŒè¯æ˜¯å¦æœ‰è¯Šæ–­ä¿¡æ¯
        if patient_data.diagnosis_info is None:
            raise HTTPException(status_code=400, detail="æ‚£è€…å°šæœªè¿›è¡Œè¯Šæ–­åˆ†æï¼Œæ— æ³•æäº¤æ£€æŸ¥ç»“æœ")
        
        # éªŒè¯æäº¤çš„æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        for test in request.submitted_tests:
            if 'test_name' not in test or 'result' not in test:
                raise HTTPException(
                    status_code=400, 
                    detail=f"æ£€æŸ¥æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦å­—æ®µ: {test}"
                )
            if not test['result'] or not test['result'].strip():
                raise HTTPException(
                    status_code=400, 
                    detail=f"æ£€æŸ¥é¡¹ç›® {test['test_name']} çš„ç»“æœä¸èƒ½ä¸ºç©º"
                )
        
        # æäº¤æ£€æŸ¥ç»“æœ
        updated_patient = patient_manager.submit_test_results(
            patient_id=patient_id,
            submitted_tests=request.submitted_tests
        )
        
        print(f">>> æˆåŠŸæäº¤ {len(request.submitted_tests)} é¡¹æ£€æŸ¥ç»“æœ")
        return updated_patient.model_dump(exclude_none=False)
        
    except HTTPException:
        raise
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æäº¤æ£€æŸ¥ç»“æœå¤±è´¥: {str(e)}")


# ============================================================================
# AIå¯¹è¯æ¥å£
# ============================================================================

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_ai(request: ChatRequest):
    """ä¸AIè¿›è¡Œå¯¹è¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹ï¼‰"""
    try:
        # éªŒè¯æ‚£è€…æ˜¯å¦å­˜åœ¨
        patient_data = patient_manager.load_patient_data(request.patient_id)
        if patient_data is None:
            raise HTTPException(status_code=404, detail="æ‚£è€…ä¸å­˜åœ¨")
        
        # ä½¿ç”¨patient_idä½œä¸ºthread_id
        config = {
            "configurable": {
                "thread_id": request.patient_id  # ç›´æ¥ä½¿ç”¨patient_idä½œä¸ºthread_id
            }
        }
        
        # å‡†å¤‡è¾“å…¥
        input_data = {
            "messages": [HumanMessage(content=request.message)],
            "patient_id": request.patient_id
        }
        
        # å¦‚æœæ˜¯é¦–æ¬¡å¯¹è¯ï¼Œåˆå§‹åŒ–æ‰€æœ‰å­—æ®µ
        if not patient_data.conversation_history:
            input_data.update({
                "type": "",
                "disease_data": {},
                "risk_factor_count": 0,
                "analysis_result": {},
                "diagnostic_tests": [],
                "user_input": "",
                "triage1_result": "",
                "triage2_result": "",
                "combined_analysis": "",
                "has_triaged": False,
                "triage_questions": ""
            })
            print(f">>> é¦–æ¬¡å¯¹è¯ï¼Œåˆå§‹åŒ–çŠ¶æ€ï¼Œthread_id: {request.patient_id}")
        
        # æ‰§è¡Œå¯¹è¯ - åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        from concurrent.futures import ThreadPoolExecutor
        loop = asyncio.get_event_loop()
        
        def run_graph_sync():
            """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„graph.invoke()"""
            return graph.invoke(input_data, config)
        
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = loop.run_in_executor(executor, run_graph_sync)
            result_state = await future
        
        # æå–AIå›å¤
        messages = result_state.get("messages", [])
        if messages:
            last_message = messages[-1]
            full_content = last_message.content if hasattr(last_message, 'content') else str(last_message)
            
            # æå–æ‰€æœ‰ <ç»“è®º> æ ‡ç­¾å†…å®¹ï¼Œç§»é™¤ <æ€è€ƒ> æ ‡ç­¾
            import re
            conclusion_matches = re.findall(r'<ç»“è®º>(.*?)</ç»“è®º>', full_content, re.DOTALL)
            if conclusion_matches:
                # åˆå¹¶æ‰€æœ‰ç»“è®º
                ai_response = '\n\n'.join([c.strip() for c in conclusion_matches])
            else:
                ai_response = re.sub(r'<æ€è€ƒ>.*?</æ€è€ƒ>', '', full_content, flags=re.DOTALL)
                ai_response = re.sub(r'<think>.*?</think>', '', ai_response, flags=re.DOTALL)
                ai_response = ai_response.strip() or full_content
        else:
            ai_response = "ç³»ç»Ÿæ— å›å¤"
        
        # ä¿å­˜å¯¹è¯å†å²
        patient_manager.add_conversation(request.patient_id, "user", request.message)
        patient_manager.add_conversation(request.patient_id, "assistant", ai_response)
        
        # é‡æ–°åŠ è½½æ‚£è€…æ•°æ®
        updated_patient_data = patient_manager.load_patient_data(request.patient_id)
        
        return ChatResponse(
            response=ai_response,
            patient_data=updated_patient_data.model_dump(exclude_none=False)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")


@app.post("/api/chat/stream")
async def chat_with_ai_stream(request: ChatRequest):
    """ä¸AIè¿›è¡Œå¯¹è¯ï¼ˆæµå¼è¾“å‡ºç‰ˆæœ¬ï¼Œæ”¯æŒæ€è€ƒè¿‡ç¨‹å±•ç¤ºï¼‰"""
    
    async def event_generator():
        try:
            # éªŒè¯æ‚£è€…æ˜¯å¦å­˜åœ¨
            patient_data = patient_manager.load_patient_data(request.patient_id)
            if patient_data is None:
                yield f"data: {json.dumps({'error': 'æ‚£è€…ä¸å­˜åœ¨'}, ensure_ascii=False)}\n\n"
                return
            
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹å¤„ç†...'}, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.1)  # ç¡®ä¿æ¶ˆæ¯è¢«å‘é€
            
            # ä½¿ç”¨patient_idä½œä¸ºthread_id
            config = {
                "configurable": {
                    "thread_id": request.patient_id
                }
            }
            
            # å‡†å¤‡è¾“å…¥
            input_data = {
                "messages": [HumanMessage(content=request.message)],
                "patient_id": request.patient_id
            }
            
            # å¦‚æœæ˜¯é¦–æ¬¡å¯¹è¯ï¼Œåˆå§‹åŒ–æ‰€æœ‰å­—æ®µ
            if not patient_data.conversation_history:
                input_data.update({
                    "type": "",
                    "disease_data": {},
                    "risk_factor_count": 0,
                    "analysis_result": {},
                    "diagnostic_tests": [],
                    "user_input": "",
                    "triage1_result": "",
                    "triage2_result": "",
                    "combined_analysis": "",
                    "has_triaged": False,
                    "triage_questions": ""
                })
            
            # ä½¿ç”¨streamæ–¹æ³•æ‰§è¡Œå¯¹è¯ï¼Œè·å–ä¸­é—´æ­¥éª¤å’Œæ€è€ƒè¿‡ç¨‹
            thinking_steps = []
            thinking_content = ""
            current_node = None
            step_counter = 0
            
            # å‘é€æ€è€ƒè¿‡ç¨‹å¼€å§‹
            yield f"data: {json.dumps({'type': 'thinking_start', 'message': 'æ­£åœ¨åˆ†æ...'}, ensure_ascii=False)}\n\n"
            
            try:
                # ä½¿ç”¨streamè·å–æ‰§è¡Œè¿‡ç¨‹ - åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œä»¥é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                import re
                from concurrent.futures import ThreadPoolExecutor
                import threading
                
                # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡ŒåŒæ­¥çš„graphæ“ä½œ
                def run_graph_stream():
                    """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œgraph.stream()"""
                    chunks = []
                    for chunk in graph.stream(input_data, config):
                        chunks.append(chunk)
                    return chunks
                
                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥æ“ä½œ
                loop = asyncio.get_event_loop()
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = loop.run_in_executor(executor, run_graph_stream)
                    chunks = await future
                
                # å¤„ç†æ”¶é›†åˆ°çš„chunks
                for chunk in chunks:
                    # chunkçš„æ ¼å¼: {node_name: state_dict}
                    for node_name, state_data in chunk.items():
                        if node_name != "__end__":
                            # èŠ‚ç‚¹æ˜¾ç¤ºåç§°
                            node_display_names = {
                                "router": "ğŸ”€ è·¯ç”±åˆ†æ",
                                "triage_node": "ğŸ¥ åˆ†è¯Šè¯„ä¼°",
                                "recommend_node": "ğŸ’Š è¯Šæ–­å»ºè®®",
                                "agen_node": "ğŸ‘¨â€âš•ï¸ ä¸“å®¶ä¼šè¯Š",
                                "query_node": "ğŸ“š çŸ¥è¯†æŸ¥è¯¢"
                            }
                            display_name = node_display_names.get(node_name, f"âš™ï¸ {node_name}")
                            
                            # æå–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰æ€è€ƒå†…å®¹ï¼ˆå¤„ç†å¤šä¸ªæ™ºèƒ½ä½“çš„æƒ…å†µï¼‰
                            all_thinking = []
                            
                            # æ–¹æ³•1ï¼šä» messages ä¸­æå–
                            messages = state_data.get("messages", [])
                            if messages:
                                for msg in messages:
                                    msg_content = msg.content if hasattr(msg, 'content') else str(msg)
                                    # æå–æ€è€ƒè¿‡ç¨‹
                                    think_matches = re.findall(r'<æ€è€ƒ>(.*?)</æ€è€ƒ>', msg_content, re.DOTALL)
                                    if not think_matches:
                                        think_matches = re.findall(r'<think>(.*?)</think>', msg_content, re.DOTALL)
                                    
                                    if think_matches:
                                        all_thinking.extend(think_matches)
                            
                            # æ–¹æ³•2ï¼šä» triage_node çš„ç‰¹æ®Šå­—æ®µæå–
                            if node_name == "triage_node":
                                # triage1_result å’Œ triage2_result
                                triage1 = state_data.get("triage1_result", "")
                                triage2 = state_data.get("triage2_result", "")
                                
                                for result in [triage1, triage2]:
                                    if result:
                                        think_matches = re.findall(r'<æ€è€ƒ>(.*?)</æ€è€ƒ>', result, re.DOTALL)
                                        if think_matches:
                                            all_thinking.extend(think_matches)
                            
                            # åˆå¹¶æ‰€æœ‰æ€è€ƒå†…å®¹
                            if all_thinking:
                                step_thinking = "\n\n---\n\n".join([t.strip() for t in all_thinking])
                            else:
                                step_thinking = ""
                            
                            step_counter += 1
                            thinking_steps.append({
                                "node": node_name,
                                "display_name": display_name,
                                "content": step_thinking,
                                "timestamp": str(loop.time())
                            })
                            
                            # æµå¼è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼ˆåˆ†æ®µå‘é€ï¼‰
                            if step_thinking:
                                # å…ˆå‘é€èŠ‚ç‚¹ä¿¡æ¯
                                yield f"data: {json.dumps({'type': 'thinking_step_start', 'node': node_name, 'display_name': display_name}, ensure_ascii=False)}\n\n"
                                await asyncio.sleep(0.05)
                                
                                # åˆ†æ®µå‘é€æ€è€ƒå†…å®¹
                                chunk_size = 50
                                for i in range(0, len(step_thinking), chunk_size):
                                    chunk_text = step_thinking[i:i+chunk_size]
                                    yield f"data: {json.dumps({'type': 'thinking_chunk', 'node': node_name, 'content': chunk_text}, ensure_ascii=False)}\n\n"
                                    await asyncio.sleep(0.02)
                                
                                # å‘é€èŠ‚ç‚¹å®Œæˆ
                                yield f"data: {json.dumps({'type': 'thinking_step_end', 'node': node_name}, ensure_ascii=False)}\n\n"
                            else:
                                # å¦‚æœæ²¡æœ‰æ€è€ƒå†…å®¹ï¼Œç›´æ¥å‘é€èŠ‚ç‚¹ä¿¡æ¯
                                yield f"data: {json.dumps({'type': 'thinking_step', 'node': node_name, 'display_name': display_name, 'content': ''}, ensure_ascii=False)}\n\n"
                            
                            await asyncio.sleep(0.1)
                
                # æ‰§è¡Œå®Œæ•´çš„invokeè·å–æœ€ç»ˆç»“æœ - åŒæ ·åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
                def run_graph_invoke():
                    """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œgraph.invoke()"""
                    return graph.invoke(input_data, config)
                
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = loop.run_in_executor(executor, run_graph_invoke)
                    result_state = await future
                
                # æå–AIå›å¤
                messages = result_state.get("messages", [])
                if messages:
                    last_message = messages[-1]
                    full_content = last_message.content if hasattr(last_message, 'content') else str(last_message)
                    
                    # æå–å¹¶æ¸…ç†å›å¤å†…å®¹
                    import re
                    
                    # 1. æå–æ‰€æœ‰ <ç»“è®º> æ ‡ç­¾å†…å®¹
                    conclusion_matches = re.findall(r'<ç»“è®º>(.*?)</ç»“è®º>', full_content, re.DOTALL)
                    if conclusion_matches:
                        # åˆå¹¶æ‰€æœ‰ç»“è®ºï¼ˆç”¨åˆ†éš”çº¿åˆ†å¼€ï¼‰
                        ai_response = '\n\n'.join([c.strip() for c in conclusion_matches])
                    else:
                        # 2. ç§»é™¤æ‰€æœ‰æ€è€ƒæ ‡ç­¾
                        ai_response = re.sub(r'<æ€è€ƒ>.*?</æ€è€ƒ>', '', full_content, flags=re.DOTALL)
                        ai_response = re.sub(r'<think>.*?</think>', '', ai_response, flags=re.DOTALL)
                        ai_response = ai_response.strip()
                        
                        if not ai_response:
                            ai_response = full_content  # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œä½¿ç”¨å®Œæ•´å†…å®¹
                else:
                    ai_response = "ç³»ç»Ÿæ— å›å¤"
                
                # å‘é€æ€è€ƒè¿‡ç¨‹ç»“æŸ
                yield f"data: {json.dumps({'type': 'thinking_end', 'steps': thinking_steps}, ensure_ascii=False)}\n\n"
                
                # æµå¼å‘é€AIå›å¤ï¼ˆé€å­—è¾“å‡ºï¼‰
                yield f"data: {json.dumps({'type': 'response_start'}, ensure_ascii=False)}\n\n"
                
                # å°†å›å¤åˆ†æ®µå‘é€ï¼ˆæ›´å°çš„å—ï¼Œæ›´æµç•…çš„æ•ˆæœï¼‰
                chunk_size = 5  # æ¯æ¬¡å‘é€5ä¸ªå­—ç¬¦
                for i in range(0, len(ai_response), chunk_size):
                    chunk_text = ai_response[i:i+chunk_size]
                    yield f"data: {json.dumps({'type': 'response_chunk', 'content': chunk_text}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.03)  # æ‰“å­—æ•ˆæœ
                
                yield f"data: {json.dumps({'type': 'response_end'}, ensure_ascii=False)}\n\n"
                
                # ä¿å­˜å¯¹è¯å†å²
                patient_manager.add_conversation(request.patient_id, "user", request.message)
                patient_manager.add_conversation(request.patient_id, "assistant", ai_response)
                
                # å‘é€å®Œæˆäº‹ä»¶
                yield f"data: {json.dumps({'type': 'done', 'response': ai_response}, ensure_ascii=False)}\n\n"
                
            except Exception as e:
                print(f">>> æµå¼å¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
        
        except Exception as e:
            print(f">>> äº‹ä»¶ç”Ÿæˆå™¨é”™è¯¯: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


# ============================================================================
# WebSocketæ”¯æŒï¼ˆå¯é€‰ï¼Œç”¨äºå®æ—¶å¯¹è¯ï¼‰
# ============================================================================

@app.websocket("/ws/chat/{patient_id}")
async def websocket_chat(websocket: WebSocket, patient_id: str):
    """WebSocketå®æ—¶å¯¹è¯"""
    await websocket.accept()
    
    try:
        # éªŒè¯æ‚£è€…æ˜¯å¦å­˜åœ¨
        patient_data = patient_manager.load_patient_data(patient_id)
        if patient_data is None:
            await websocket.send_json({"error": "æ‚£è€…ä¸å­˜åœ¨"})
            await websocket.close()
            return
        
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_text()
            message_data = json.loads(data)
            user_message = message_data.get("message", "")
            
            if not user_message:
                continue
            
            # å¤„ç†å¯¹è¯ï¼ˆä¸HTTPæ¥å£ç›¸åŒçš„é€»è¾‘ï¼‰
            config = {
                "configurable": {
                    "thread_id": patient_id
                }
            }
            
            input_data = {
                "messages": [HumanMessage(content=user_message)],
                "patient_id": patient_id
            }
            
            # æ‰§è¡Œå¯¹è¯ - åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
            from concurrent.futures import ThreadPoolExecutor
            loop = asyncio.get_event_loop()
            
            def run_graph_sync():
                """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„graph.invoke()"""
                return graph.invoke(input_data, config)
            
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = loop.run_in_executor(executor, run_graph_sync)
                result_state = await future
            
            # æå–AIå›å¤
            messages = result_state.get("messages", [])
            if messages:
                last_message = messages[-1]
                ai_response = last_message.content if hasattr(last_message, 'content') else str(last_message)
            else:
                ai_response = "ç³»ç»Ÿæ— å›å¤"
            
            # ä¿å­˜å¯¹è¯å†å²
            patient_manager.add_conversation(patient_id, "user", user_message)
            patient_manager.add_conversation(patient_id, "assistant", ai_response)
            
            # å‘é€å›å¤
            await websocket.send_json({
                "response": ai_response,
                "timestamp": patient_manager.load_patient_data(patient_id).updated_at
            })
            
    except WebSocketDisconnect:
        print(f"WebSocketæ–­å¼€è¿æ¥: {patient_id}")
    except Exception as e:
        print(f"WebSocketé”™è¯¯: {e}")
        await websocket.send_json({"error": str(e)})
        await websocket.close()


# ============================================================================
# çŸ¥è¯†å›¾è°±æ„å»ºæ¥å£
# ============================================================================

@app.post("/api/knowledge/upload")
async def upload_knowledge_document(file: UploadFile = File(...)):
    """
    ä¸Šä¼ åŒ»å­¦æ–‡çŒ®å¹¶è¿›è¡Œåˆæ­¥å¤„ç†
    æ­¥éª¤1ï¼šä¸Šä¼ PDF -> è½¬æ¢ä¸ºHTML -> æ¸…æ´—HTML
    """
    try:
        if not file.filename.endswith('.pdf'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ–‡ä»¶")
        
        # æ£€æŸ¥KnowledgeWorkflowæ˜¯å¦å¯ç”¨
        if KnowledgeWorkflow is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±å·¥ä½œæµæœªåˆå§‹åŒ–")
        
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = KnowledgeWorkflow()
        
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        doc_name = Path(file.filename).stem
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„PDF
        temp_dir = Path("temp_uploads")
        temp_dir.mkdir(exist_ok=True)
        temp_pdf_path = temp_dir / file.filename
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with open(temp_pdf_path, 'wb') as f:
            content = await file.read()
            f.write(content)
        
        print(f">>> æ¥æ”¶åˆ°æ–‡ä»¶: {file.filename}, å¤§å°: {len(content)} bytes")
        
        # åˆ›å»ºå·¥ä½œç›®å½•
        work_dir = get_path("knowledges_dir") / doc_name
        work_dir.mkdir(parents=True, exist_ok=True)
        
        # æ­¥éª¤1: ä½¿ç”¨doclingæ‰«ææ–‡çŒ®
        html_raw = workflow._step1_docling_scan(temp_pdf_path, work_dir)
        if not html_raw:
            raise HTTPException(status_code=500, detail="PDFè§£æå¤±è´¥")
        
        # æ­¥éª¤2: æ¸…æ´—HTML
        html_cleaned = workflow._step2_clean_html(html_raw, work_dir)
        if not html_cleaned:
            raise HTTPException(status_code=500, detail="HTMLæ¸…æ´—å¤±è´¥")
        
        # æ­¥éª¤3: è½¬æ¢ä¸ºmarkdownï¼ˆç”¨äºåç»­çš„å®ä½“æŠ½å–ï¼‰
        markdown_content = workflow._step3_convert_to_markdown(html_cleaned, work_dir)
        if not markdown_content:
            raise HTTPException(status_code=500, detail="Markdownè½¬æ¢å¤±è´¥")
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        temp_pdf_path.unlink()
        
        print(f">>> æ–‡æ¡£å¤„ç†å®Œæˆ: {doc_name}")
        
        return {
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "document_name": doc_name,
            "html_raw": html_raw,
            "html_cleaned": html_cleaned,
            "work_dir": str(work_dir)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")


@app.post("/api/knowledge/extract")
async def extract_entities(request: ExtractEntitiesRequest):
    """
    å®ä½“æŠ½å–
    æ­¥éª¤4ï¼šä»markdownä¸­æŠ½å–å®ä½“å’Œå…³ç³»
    """
    try:
        # æ£€æŸ¥KnowledgeWorkflowæ˜¯å¦å¯ç”¨
        if KnowledgeWorkflow is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±å·¥ä½œæµæœªåˆå§‹åŒ–")
        
        # å·¥ä½œç›®å½•
        work_dir = get_path("knowledges_dir") / request.document_name
        if not work_dir.exists():
            raise HTTPException(status_code=404, detail="æ–‡æ¡£å·¥ä½œç›®å½•ä¸å­˜åœ¨")
        
        # è¯»å–markdownæ–‡ä»¶
        markdown_path = work_dir / "03_document.md"
        if not markdown_path.exists():
            raise HTTPException(status_code=404, detail="Markdownæ–‡ä»¶ä¸å­˜åœ¨")
        
        with open(markdown_path, 'r', encoding='utf-8') as f:
            markdown_content = f.read()
        
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = KnowledgeWorkflow()
        
        # æ­¥éª¤4: å®ä½“æŠ½å–
        print(f">>> å¼€å§‹å®ä½“æŠ½å–: {request.document_name}")
        knowledge_graph = workflow._step4_entity_extraction(markdown_content, work_dir)
        
        if not knowledge_graph:
            raise HTTPException(status_code=500, detail="å®ä½“æŠ½å–å¤±è´¥")
        
        print(f">>> å®ä½“æŠ½å–å®Œæˆ: {len(knowledge_graph['entities'])} ä¸ªå®ä½“, {len(knowledge_graph['relationships'])} ä¸ªå…³ç³»")
        
        return {
            "message": "å®ä½“æŠ½å–å®Œæˆ",
            "entities": knowledge_graph['entities'],
            "relationships": knowledge_graph['relationships'],
            "metadata": knowledge_graph.get('metadata', {})
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å®ä½“æŠ½å–å¤±è´¥: {str(e)}")


@app.post("/api/knowledge/build")
async def build_knowledge_graph(request: BuildGraphRequest):
    """
    æ„å»ºçŸ¥è¯†å›¾è°±
    æ­¥éª¤5ï¼šå°†ç¼–è¾‘åçš„å®ä½“å’Œå…³ç³»å¯¼å…¥Neo4j
    """
    try:
        # æ£€æŸ¥KnowledgeWorkflowæ˜¯å¦å¯ç”¨
        if KnowledgeWorkflow is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±å·¥ä½œæµæœªåˆå§‹åŒ–")
        
        # å·¥ä½œç›®å½•
        work_dir = get_path("knowledges_dir") / request.document_name
        if not work_dir.exists():
            raise HTTPException(status_code=404, detail="æ–‡æ¡£å·¥ä½œç›®å½•ä¸å­˜åœ¨")
        
        # æ›´æ–°çŸ¥è¯†å›¾è°±JSONï¼ˆä¿å­˜ç”¨æˆ·ç¼–è¾‘åçš„ç‰ˆæœ¬ï¼‰
        from datetime import datetime
        
        entity_type_counts = {}
        for entity in request.entities:
            entity_type = entity['entity_type']
            entity_type_counts[entity_type] = entity_type_counts.get(entity_type, 0) + 1
        
        knowledge_graph = {
            "entities": request.entities,
            "relationships": request.relationships,
            "metadata": {
                "extraction_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "entity_count": len(request.entities),
                "relationship_count": len(request.relationships),
                "entity_type_counts": entity_type_counts,
                "edited": True
            }
        }
        
        # ä¿å­˜æ›´æ–°åçš„JSON
        json_path = work_dir / "04_knowledge_graph.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_graph, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = KnowledgeWorkflow()
        
        # æ­¥éª¤5: å¯¼å…¥Neo4j
        print(f">>> å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±: {request.document_name}")
        success = workflow._step5_import_to_neo4j(knowledge_graph, work_dir)
        
        if not success:
            print(">>> è­¦å‘Š: Neo4jå¯¼å…¥å¤±è´¥ï¼Œä½†JSONå·²ä¿å­˜")
        
        # æ­¥éª¤6: å¯¹SymptomèŠ‚ç‚¹è¿›è¡Œå‘é‡åŒ–ï¼ˆä»…åœ¨Neo4jå¯¼å…¥æˆåŠŸæ—¶ï¼‰
        symptom_vectorize_success = False
        if success and SymptomVectorizer is not None:
            try:
                print(f">>> å¼€å§‹å¯¹ {request.document_name} çš„SymptomèŠ‚ç‚¹è¿›è¡Œå‘é‡åŒ–...")
                
                # ä»å…¨å±€é…ç½®è·å–å‚æ•°
                from config import NEO4J_CONFIG
                
                # åˆ›å»ºå‘é‡åŒ–å™¨å®ä¾‹
                vectorizer = SymptomVectorizer(
                    uri=NEO4J_CONFIG["uri"],
                    user=NEO4J_CONFIG["user"],
                    password=NEO4J_CONFIG["password"],
                    model_path=str(get_path("m3e_model"))
                )
                
                # ä¸ºå½“å‰æ–‡æ¡£åˆ›å»ºå”¯ä¸€çš„ç´¢å¼•åç§°
                doc_name_safe = request.document_name.replace(' ', '_').replace('-', '_')
                index_name = f"symptom_vectors_{doc_name_safe}"
                
                # åˆ›å»ºç—‡çŠ¶å‘é‡ç´¢å¼•ï¼ˆåªå¤„ç†å½“å‰æ–‡æ¡£ç›¸å…³çš„ç—‡çŠ¶èŠ‚ç‚¹ï¼‰
                vector_store = vectorizer.create_enhanced_symptom_vectors(
                    index_name=index_name,
                    document_name=request.document_name
                )
                
                if vector_store:
                    symptom_vectorize_success = True
                    print(f">>> SymptomèŠ‚ç‚¹å‘é‡åŒ–å®Œæˆï¼Œç´¢å¼•å: {index_name}")
                else:
                    print(f">>> SymptomèŠ‚ç‚¹å‘é‡åŒ–å¤±è´¥")
                    
            except Exception as e:
                print(f">>> SymptomèŠ‚ç‚¹å‘é‡åŒ–å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
        
        # æ­¥éª¤7: ä½¿ç”¨Redisè¿›è¡ŒRAGå‘é‡åŒ–ï¼ˆçŸ¥è¯†å›¾è°±æ–‡æ¡£å’Œå®ä½“ï¼‰
        rag_vectorize_success = False
        rag_results = {}
        if KnowledgeRAGVectorizer is not None:
            try:
                print(f">>> å¼€å§‹å¯¹ {request.document_name} è¿›è¡ŒRAGå‘é‡åŒ–...")
                
                # åˆ›å»ºRAGå‘é‡åŒ–å™¨å®ä¾‹
                rag_vectorizer = KnowledgeRAGVectorizer(
                    host='localhost',
                    port=6379,
                    password=None
                )
                
                # æ‰§è¡Œå‘é‡åŒ–ï¼ˆåªå‘é‡åŒ–markdownæ–‡æ¡£ï¼Œå®ä½“å·²åœ¨Neo4jä¸­ï¼‰
                rag_results = rag_vectorizer.vectorize_knowledge_document(
                    document_name=request.document_name,
                    vectorize_markdown=True,   # å‘é‡åŒ–markdownæ–‡æ¡£ç”¨äºè¯­ä¹‰æ£€ç´¢
                    vectorize_entities=False   # å®ä½“åœ¨Neo4jä¸­ï¼Œæ— éœ€é‡å¤å‘é‡åŒ–
                )
                
                if rag_results.get('markdown_vectorized') or rag_results.get('entities_vectorized'):
                    rag_vectorize_success = True
                    print(f">>> RAGå‘é‡åŒ–å®Œæˆ")
                    print(f"    - Markdownæ–‡æ¡£: {rag_results.get('markdown_chunks', 0)} ä¸ªæ–‡æœ¬å—")
                    print(f"    - çŸ¥è¯†å›¾è°±å®ä½“: {rag_results.get('entity_count', 0)} ä¸ªå®ä½“")
                else:
                    print(f">>> RAGå‘é‡åŒ–å¤±è´¥")
                    
            except Exception as e:
                print(f">>> RAGå‘é‡åŒ–å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
        
        print(f">>> çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ: {request.document_name}")
        
        # æ­¥éª¤8: æ³¨å†Œåˆ°æ•°æ®ç®¡ç†å™¨
        if data_manager is not None:
            try:
                # æ”¶é›†æ‰€æœ‰Redisç´¢å¼•
                redis_indices = []
                if rag_vectorize_success and rag_results.get('markdown_vectorized'):
                    doc_name_safe = request.document_name.replace(' ', '_').replace('-', '_')
                    redis_indices.append(f"kg_{doc_name_safe}")
                
                if symptom_vectorize_success:
                    doc_name_safe = request.document_name.replace(' ', '_').replace('-', '_')
                    redis_indices.append(f"symptom_vectors_{doc_name_safe}")
                
                # æ³¨å†Œæ–‡æ¡£
                data_manager.register_document(
                    document_name=request.document_name,
                    redis_indices=redis_indices,
                    neo4j_labels=None,  # è‡ªåŠ¨æ£€æµ‹
                    entity_count=len(request.entities),
                    relationship_count=len(request.relationships)
                )
                print(f">>> å·²æ³¨å†Œåˆ°æ•°æ®ç®¡ç†å™¨")
                
            except Exception as e:
                print(f">>> æ³¨å†Œåˆ°æ•°æ®ç®¡ç†å™¨å¤±è´¥: {e}")
        
        return {
            "message": "çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ" + 
                      (" (å«ç—‡çŠ¶å‘é‡åŒ–)" if symptom_vectorize_success else "") + 
                      (" (å«RAGå‘é‡åŒ–)" if rag_vectorize_success else ""),
            "neo4j_imported": success,
            "symptom_vectorized": symptom_vectorize_success,
            "rag_vectorized": rag_vectorize_success,
            "rag_results": rag_results,
            "entity_count": len(request.entities),
            "relationship_count": len(request.relationships)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"çŸ¥è¯†å›¾è°±æ„å»ºå¤±è´¥: {str(e)}")


@app.get("/api/knowledge/export/{document_name}")
async def export_knowledge_graph(document_name: str):
    """å¯¼å‡ºçŸ¥è¯†å›¾è°±JSONæ–‡ä»¶"""
    try:
        work_dir = get_path("knowledges_dir") / document_name
        json_path = work_dir / "04_knowledge_graph.json"
        
        if not json_path.exists():
            raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨")
        
        return FileResponse(
            path=json_path,
            filename=f"{document_name}_knowledge_graph.json",
            media_type="application/json"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")


@app.get("/api/knowledge/list")
async def list_knowledge_documents():
    """åˆ—å‡ºæ‰€æœ‰å·²å¤„ç†çš„æ–‡æ¡£"""
    try:
        knowledges_dir = get_path("knowledges_dir")
        if not knowledges_dir.exists():
            return {"documents": []}
        
        documents = []
        for dir_path in knowledges_dir.iterdir():
            if dir_path.is_dir():
                # æ£€æŸ¥æ˜¯å¦æœ‰çŸ¥è¯†å›¾è°±JSON
                json_path = dir_path / "04_knowledge_graph.json"
                has_graph = json_path.exists()
                
                # è¯»å–metadata
                metadata = {}
                if has_graph:
                    try:
                        with open(json_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            metadata = data.get('metadata', {})
                    except:
                        pass
                
                documents.append({
                    "name": dir_path.name,
                    "path": str(dir_path),
                    "has_graph": has_graph,
                    "metadata": metadata
                })
        
        return {"documents": documents}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/knowledge/load/{document_name}")
async def load_knowledge_document(document_name: str):
    """åŠ è½½å·²å­˜åœ¨æ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        work_dir = get_path("knowledges_dir") / document_name
        if not work_dir.exists():
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        # è¯»å–HTMLæ–‡ä»¶
        raw_html_path = work_dir / "01_raw.html"
        cleaned_html_path = work_dir / "02_cleaned.html"
        json_path = work_dir / "04_knowledge_graph.json"
        
        html_raw = ""
        html_cleaned = ""
        entities = []
        relationships = []
        
        if raw_html_path.exists():
            with open(raw_html_path, 'r', encoding='utf-8') as f:
                html_raw = f.read()
        
        if cleaned_html_path.exists():
            with open(cleaned_html_path, 'r', encoding='utf-8') as f:
                html_cleaned = f.read()
        
        has_knowledge_graph = False
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                entities = data.get('entities', [])
                relationships = data.get('relationships', [])
                has_knowledge_graph = True
        
        return {
            "document_name": document_name,
            "html_raw": html_raw,
            "html_cleaned": html_cleaned,
            "entities": entities,
            "relationships": relationships,
            "has_knowledge_graph": has_knowledge_graph
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åŠ è½½æ–‡æ¡£å¤±è´¥: {str(e)}")


@app.delete("/api/knowledge/delete/{document_name}")
async def delete_knowledge_document(
    document_name: str,
    delete_files: bool = True,
    delete_redis: bool = True,
    delete_neo4j: bool = True
):
    """
    åˆ é™¤çŸ¥è¯†æ–‡æ¡£åŠå…¶æ‰€æœ‰ç›¸å…³èµ„æº
    
    Args:
        document_name: æ–‡æ¡£åç§°
        delete_files: æ˜¯å¦åˆ é™¤æ–‡ä»¶å¤¹ï¼ˆé»˜è®¤trueï¼‰
        delete_redis: æ˜¯å¦åˆ é™¤Redisç´¢å¼•ï¼ˆé»˜è®¤trueï¼‰
        delete_neo4j: æ˜¯å¦åˆ é™¤Neo4jèŠ‚ç‚¹ï¼ˆé»˜è®¤trueï¼‰
    """
    try:
        if data_manager is None:
            raise HTTPException(status_code=500, detail="æ•°æ®ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        print(f">>> æ”¶åˆ°åˆ é™¤è¯·æ±‚: {document_name}")
        print(f"    - åˆ é™¤æ–‡ä»¶: {delete_files}")
        print(f"    - åˆ é™¤Redis: {delete_redis}")
        print(f"    - åˆ é™¤Neo4j: {delete_neo4j}")
        
        # æ‰§è¡Œåˆ é™¤
        result = data_manager.delete_document(
            document_name=document_name,
            delete_files=delete_files,
            delete_redis=delete_redis,
            delete_neo4j=delete_neo4j,
            dry_run=False
        )
        
        if result['errors']:
            return {
                "success": False,
                "message": f"åˆ é™¤è¿‡ç¨‹ä¸­é‡åˆ° {len(result['errors'])} ä¸ªé”™è¯¯",
                "result": result
            }
        else:
            return {
                "success": True,
                "message": "æ–‡æ¡£åˆ é™¤æˆåŠŸ",
                "result": result
            }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")


@app.post("/api/knowledge/sync-metadata")
async def sync_metadata():
    """åŒæ­¥å…ƒæ•°æ®ï¼ˆæ‰«ææ‰€æœ‰æ–‡æ¡£å¹¶æ›´æ–°å…ƒæ•°æ®ï¼‰"""
    try:
        if data_manager is None:
            raise HTTPException(status_code=500, detail="æ•°æ®ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        data_manager.sync_metadata()
        stats = data_manager.get_storage_stats()
        
        return {
            "success": True,
            "message": "å…ƒæ•°æ®åŒæ­¥å®Œæˆ",
            "stats": stats
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åŒæ­¥å…ƒæ•°æ®å¤±è´¥: {str(e)}")


@app.get("/api/knowledge/stats")
async def get_storage_stats():
    """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if data_manager is None:
            raise HTTPException(status_code=500, detail="æ•°æ®ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        stats = data_manager.get_storage_stats()
        return stats
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.post("/api/knowledge/cleanup-orphaned")
async def cleanup_orphaned_resources(dry_run: bool = True):
    """
    æ¸…ç†å­¤ç«‹èµ„æº
    
    Args:
        dry_run: æ˜¯å¦ä¸ºé¢„æ¼”æ¨¡å¼ï¼ˆé»˜è®¤trueï¼Œåªæ£€æµ‹ä¸åˆ é™¤ï¼‰
    """
    try:
        if data_manager is None:
            raise HTTPException(status_code=500, detail="æ•°æ®ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        print(f">>> å¼€å§‹æ¸…ç†å­¤ç«‹èµ„æºï¼ˆ{'é¢„æ¼”' if dry_run else 'å®é™…åˆ é™¤'}ï¼‰...")
        
        result = data_manager.cleanup_orphaned_resources(dry_run=dry_run)
        
        message = "å­¤ç«‹èµ„æºæ£€æµ‹å®Œæˆ" if dry_run else "å­¤ç«‹èµ„æºæ¸…ç†å®Œæˆ"
        
        return {
            "success": True,
            "message": message,
            "result": result
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å­¤ç«‹èµ„æºå¤±è´¥: {str(e)}")


# ============================================================================
# å¯åŠ¨æœåŠ¡
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    from pathlib import Path
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆé¿å…ç¡¬ç¼–ç è·¯å¾„ï¼‰
    project_root = str(Path(__file__).parent.resolve())
    
    # ä½¿ç”¨8012ç«¯å£ï¼Œé¿å…ä¸MCPæœåŠ¡å™¨(8000)å’Œå…¶ä»–æœåŠ¡å†²çª
    # å¯ç”¨çƒ­é‡è½½ï¼šä»£ç ä¿®æ”¹åè‡ªåŠ¨é‡å¯ï¼Œæ— éœ€æ‰‹åŠ¨é‡å¯
    uvicorn.run(
        "backend_api:app",  # ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ä»¥æ”¯æŒçƒ­é‡è½½
        host="0.0.0.0",
        port=8012,
        reload=True,  # ğŸ”¥ å¯ç”¨çƒ­é‡è½½
        reload_dirs=[project_root],  # ç›‘æ§æ•´ä¸ªé¡¹ç›®ç›®å½•
        reload_includes=["*.py"],  # ç›‘æ§Pythonæ–‡ä»¶
        log_level="info"  # æ—¥å¿—çº§åˆ«
    )

